<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Welcome to Levine&#39;s Wikis</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="12345678&apos;&apos;&apos;A Multilayer Perceptron implementation example using TensorFlow library.This example is using the MNIST database of handwritten digits(http://yann.lecun.com/exdb/mnist/)Author: Aymeric Dami">
<meta property="og:type" content="article">
<meta property="og:title" content="Welcome to Levine's Wikis">
<meta property="og:url" content="http://levinehuang.github.io/2017/08/08/A05-MI/02-TensorFlow/multilayer_perceptron/index.html">
<meta property="og:site_name" content="Welcome to Levine's Wikis">
<meta property="og:description" content="12345678&apos;&apos;&apos;A Multilayer Perceptron implementation example using TensorFlow library.This example is using the MNIST database of handwritten digits(http://yann.lecun.com/exdb/mnist/)Author: Aymeric Dami">
<meta property="og:updated_time" content="2017-08-08T01:30:45.989Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Welcome to Levine's Wikis">
<meta name="twitter:description" content="12345678&apos;&apos;&apos;A Multilayer Perceptron implementation example using TensorFlow library.This example is using the MNIST database of handwritten digits(http://yann.lecun.com/exdb/mnist/)Author: Aymeric Dami">
  
    <link rel="alternate" href="/atom.xml" title="Welcome to Levine&#39;s Wikis" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/wiki/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/wiki/" id="logo">Welcome to Levine&#39;s Wikis</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/wiki/">Home</a>
        
          <a class="main-nav-link" href="/wiki/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://levinehuang.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-A05-MI/02-TensorFlow/multilayer_perceptron" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/wiki/2017/08/08/A05-MI/02-TensorFlow/multilayer_perceptron/" class="article-date">
  <time datetime="2017-08-08T01:26:33.729Z" itemprop="datePublished">2017-08-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">A Multilayer Perceptron implementation example using TensorFlow library.</div><div class="line">This example is using the MNIST database of handwritten digits</div><div class="line">(http://yann.lecun.com/exdb/mnist/)</div><div class="line"></div><div class="line">Author: Aymeric Damien</div><div class="line">Project: https://github.com/aymericdamien/TensorFlow-Examples/</div><div class="line">'''</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Import MINST data</span></div><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">"../../data/"</span>, one_hot=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div></pre></td></tr></table></figure>
<pre><code>Extracting ../../data/train-images-idx3-ubyte.gz
Extracting ../../data/train-labels-idx1-ubyte.gz
Extracting ../../data/t10k-images-idx3-ubyte.gz
Extracting ../../data/t10k-labels-idx1-ubyte.gz
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Parameters</span></div><div class="line">learning_rate = <span class="number">0.001</span></div><div class="line">training_epochs = <span class="number">15</span></div><div class="line">batch_size = <span class="number">100</span></div><div class="line">display_step = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># Network Parameters</span></div><div class="line">n_hidden_1 = <span class="number">256</span> <span class="comment"># 1st layer number of features</span></div><div class="line">n_hidden_2 = <span class="number">256</span> <span class="comment"># 2nd layer number of features</span></div><div class="line">n_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></div><div class="line">n_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></div><div class="line"></div><div class="line"><span class="comment"># tf Graph input</span></div><div class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, n_input])</div><div class="line">y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, n_classes])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Create model</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multilayer_perceptron</span><span class="params">(x, weights, biases)</span>:</span></div><div class="line">    <span class="comment"># Hidden layer with RELU activation</span></div><div class="line">    layer_1 = tf.add(tf.matmul(x, weights[<span class="string">'h1'</span>]), biases[<span class="string">'b1'</span>])</div><div class="line">    layer_1 = tf.nn.relu(layer_1)</div><div class="line">    <span class="comment"># Hidden layer with RELU activation</span></div><div class="line">    layer_2 = tf.add(tf.matmul(layer_1, weights[<span class="string">'h2'</span>]), biases[<span class="string">'b2'</span>])</div><div class="line">    layer_2 = tf.nn.relu(layer_2)</div><div class="line">    <span class="comment"># Output layer with linear activation</span></div><div class="line">    out_layer = tf.matmul(layer_2, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</div><div class="line">    <span class="keyword">return</span> out_layer</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Store layers weight &amp; bias</span></div><div class="line">weights = &#123;</div><div class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</div><div class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_2, n_classes]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    <span class="string">'b1'</span>: tf.Variable(tf.random_normal([n_hidden_1])),</div><div class="line">    <span class="string">'b2'</span>: tf.Variable(tf.random_normal([n_hidden_2])),</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_classes]))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Construct model</span></div><div class="line">pred = multilayer_perceptron(x, weights, biases)</div><div class="line"></div><div class="line"><span class="comment"># Define loss and optimizer</span></div><div class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</div><div class="line"></div><div class="line"><span class="comment"># Initializing the variables</span></div><div class="line">init = tf.global_variables_initializer()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</div><div class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]]</div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    print(sess.run(tf.equal(A, B)))</div></pre></td></tr></table></figure>
<pre><code>[[ True  True  True False False]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># tf.argmax(vector, 1)：返回的是vector中的最大值的索引号，如果vector是一个向量，那就返回一个值，</span></div><div class="line"><span class="comment"># 如果是一个矩阵，那就返回一个向量，这个向量的每一个维度都是相对应矩阵行的最大值元素的索引号。</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]  </div><div class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>]]  </div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:  </div><div class="line">    print(sess.run(tf.argmax(A, <span class="number">1</span>)))  </div><div class="line">    print(sess.run(tf.argmax(B, <span class="number">1</span>)))</div><div class="line"></div><div class="line"><span class="comment"># tf.cast：用于改变某个张量的数据类型</span></div><div class="line"></div><div class="line">A = tf.convert_to_tensor(np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">5</span>]]))  </div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:  </div><div class="line">    print(A.dtype)</div><div class="line">    b = tf.cast(A, tf.float32)  </div><div class="line">    print(b.dtype)</div></pre></td></tr></table></figure>
<pre><code>[4]
[2 1]
&lt;dtype: &apos;int64&apos;&gt;
&lt;dtype: &apos;float32&apos;&gt;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Launch the graph</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(init)</div><div class="line"></div><div class="line">    <span class="comment"># Training cycle</span></div><div class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</div><div class="line">        avg_cost = <span class="number">0.</span></div><div class="line">        total_batch = int(mnist.train.num_examples/batch_size)</div><div class="line">        <span class="comment"># Loop over all batches</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</div><div class="line">            batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">            <span class="comment"># Run optimization op (backprop) and cost op (to get loss value)</span></div><div class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_x,</div><div class="line">                                                          y: batch_y&#125;)</div><div class="line">            <span class="comment"># Compute average loss</span></div><div class="line">            avg_cost += c / total_batch</div><div class="line">        <span class="comment"># Display logs per epoch step</span></div><div class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch+<span class="number">1</span>), <span class="string">"cost="</span>, \</div><div class="line">                <span class="string">"&#123;:.9f&#125;"</span>.format(avg_cost))</div><div class="line">    print(<span class="string">"Optimization Finished!"</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Test model</span></div><div class="line">    correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</div><div class="line">    <span class="comment"># Calculate accuracy</span></div><div class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</div><div class="line">    print(<span class="string">"Accuracy:"</span>, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</div></pre></td></tr></table></figure>
<pre><code>Epoch: 0001 cost= 201.333574999
Epoch: 0002 cost= 46.010647814
Epoch: 0003 cost= 28.918377875
Epoch: 0004 cost= 20.020559532
Epoch: 0005 cost= 14.741128482
Epoch: 0006 cost= 11.113235143
Epoch: 0007 cost= 8.444069761
Epoch: 0008 cost= 6.217341204
Epoch: 0009 cost= 4.772409531
Epoch: 0010 cost= 3.578625235
Epoch: 0011 cost= 2.738378037
Epoch: 0012 cost= 1.975170798
Epoch: 0013 cost= 1.481307366
Epoch: 0014 cost= 1.183054283
Epoch: 0015 cost= 0.933368129
Optimization Finished!
Accuracy: 0.9483
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://levinehuang.github.io/wiki/2017/08/08/A05-MI/02-TensorFlow/multilayer_perceptron/" data-id="cj8ijf1uj001oyoo0t47emap8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/wiki/2017/05/07/A05-MI/03-SparkMLlib/SparkMLlib之01-Spark机器学习库介绍/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/DeepLearning/">DeepLearning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/DeepLearning/Keras/">Keras</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/Tools/">Tools</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/Tools/hexo/">hexo</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/language/">language</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/language/scala/">scala</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/日志/">日志</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wiki/categories/日志/运维/">运维</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/AI/">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Keras/">Keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/MI/">MI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/MachineLearning/">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Scala/">Scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/Test/">Test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/package/">package</a></li><li class="tag-list-item"><a class="tag-list-link" href="/wiki/tags/pip/">pip</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/wiki/tags/AI/" style="font-size: 20px;">AI</a> <a href="/wiki/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/wiki/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/wiki/tags/MI/" style="font-size: 20px;">MI</a> <a href="/wiki/tags/MachineLearning/" style="font-size: 10px;">MachineLearning</a> <a href="/wiki/tags/Python/" style="font-size: 10px;">Python</a> <a href="/wiki/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/wiki/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/wiki/tags/Test/" style="font-size: 10px;">Test</a> <a href="/wiki/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/wiki/tags/package/" style="font-size: 10px;">package</a> <a href="/wiki/tags/pip/" style="font-size: 10px;">pip</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/wiki/archives/2016/11/">November 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/wiki/2017/08/08/A05-MI/02-TensorFlow/multilayer_perceptron/">(no title)</a>
          </li>
        
          <li>
            <a href="/wiki/2017/05/07/A05-MI/03-SparkMLlib/SparkMLlib之01-Spark机器学习库介绍/">(no title)</a>
          </li>
        
          <li>
            <a href="/wiki/2017/03/22/A01-BigData/02-Spark/SparkSQL/">(no title)</a>
          </li>
        
          <li>
            <a href="/wiki/2017/03/09/A05-MI/10-DL理论/DL之05-RNN/">(no title)</a>
          </li>
        
          <li>
            <a href="/wiki/2017/03/01/A05-MI/10-DL理论/LSTM/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Levine Huang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/wiki/" class="mobile-nav-link">Home</a>
  
    <a href="/wiki/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/wiki/fancybox/jquery.fancybox.css">
  <script src="/wiki/fancybox/jquery.fancybox.pack.js"></script>


<script src="/wiki/js/script.js"></script>

  </div>
</body>
</html>